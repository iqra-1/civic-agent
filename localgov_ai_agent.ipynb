{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKMlrJ-wyRvK"
      },
      "source": [
        "# ğŸ›ï¸ LocalGov AI Agent â€” Dublin City Council Assistant\n",
        "> End-to-end agentic RAG system using free LLMs (Mistral-7B), scraped council data, and multi-agent reasoning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuFCWjUJ4MXs"
      },
      "source": [
        "## 1. Setup & Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGusP44mInwX",
        "outputId": "2bc488da-b46d-4951-bf80-28a137f26882"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: transformers 4.57.3\n",
            "Uninstalling transformers-4.57.3:\n",
            "  Successfully uninstalled transformers-4.57.3\n",
            "Found existing installation: tokenizers 0.22.1\n",
            "Uninstalling tokenizers-0.22.1:\n",
            "  Successfully uninstalled tokenizers-0.22.1\n",
            "Found existing installation: langchain 1.2.0\n",
            "Uninstalling langchain-1.2.0:\n",
            "  Successfully uninstalled langchain-1.2.0\n",
            "Found existing installation: langchain-core 1.2.1\n",
            "Uninstalling langchain-core-1.2.1:\n",
            "  Successfully uninstalled langchain-core-1.2.1\n",
            "\u001b[33mWARNING: Skipping langchain-community as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping crewai as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping llama-cpp-python as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: numpy 2.0.2\n",
            "Uninstalling numpy-2.0.2:\n",
            "  Successfully uninstalled numpy-2.0.2\n",
            "Found existing installation: scipy 1.16.3\n",
            "Uninstalling scipy-1.16.3:\n",
            "  Successfully uninstalled scipy-1.16.3\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m102.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "peft 0.18.0 requires transformers, which is not installed.\n",
            "torchtune 0.6.1 requires tokenizers, which is not installed.\n",
            "sentence-transformers 5.2.0 requires transformers<6.0.0,>=4.41.0, which is not installed.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.2.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.7/50.7 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m80.4/80.4 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m68.6/68.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m133.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m110.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m484.9/484.9 kB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m102.8/102.8 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m102.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m642.9/642.9 kB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m19.9/19.9 MB\u001b[0m \u001b[31m94.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m160.9/160.9 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m122.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m250.1/250.1 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m358.8/358.8 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m96.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m118.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m226.4/226.4 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m113.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m94.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m99.2/99.2 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m121.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m123.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.2.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mâœ… Installation complete! Now restart the runtime.\n",
            "âš ï¸  Go to: Runtime â†’ Restart runtime\n",
            "Then re-run your imports.\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Uninstall conflicting packages\n",
        "!pip uninstall -y transformers tokenizers langchain langchain-core langchain-community crewai llama-cpp-python numpy scipy\n",
        "\n",
        "# Step 2: Install compatible NumPy and SciPy FIRST\n",
        "!pip install -q \"numpy>=2.0,<2.3\" \"scipy>=1.13.0\"\n",
        "\n",
        "# Step 3: Install everything else\n",
        "!pip install -q \\\n",
        "    \"transformers>=4.44.0\" \\\n",
        "    \"tokenizers>=0.19.1\" \\\n",
        "    \"sentence-transformers>=3.0.1\" \\\n",
        "    \"faiss-cpu>=1.8.0\" \\\n",
        "    \"langchain-core>=1.0.0\" \\\n",
        "    \"langchain-text-splitters>=0.2.4\" \\\n",
        "    \"langchain>=0.2.16\" \\\n",
        "    \"langchain-community>=0.2.16\" \\\n",
        "    \"crewai>=0.121.1\" \\\n",
        "    \"llama-cpp-python>=0.2.87\" \\\n",
        "    \"gradio>=4.40.0\" \\\n",
        "    \"beautifulsoup4\" \\\n",
        "    \"requests\" \\\n",
        "    \"accelerate\" \\\n",
        "    \"protobuf\"\n",
        "\n",
        "print(\"âœ… Installation complete! Now restart the runtime.\")\n",
        "print(\"âš ï¸  Go to: Runtime â†’ Restart runtime\")\n",
        "print(\"Then re-run your imports.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eDz3BuUkKKoh"
      },
      "outputs": [],
      "source": [
        "# ! pip install --upgrade transformers accelerate protobuf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "27t5P1BDx_H4"
      },
      "outputs": [],
      "source": [
        "# Restart runtime if needed (Colab sometimes requires it after llama-cpp install)\n",
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucxLRIw_4btx"
      },
      "source": [
        "## 2. Enable GPU & Download Mistral-7B (GGUF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "LuEfcnlWx_lD"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocXN6kbRyDHD",
        "outputId": "734bea88-3c9f-4237-f387-f6bc3ac76839"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Dec 25 16:03:09 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "jf8TkTAgyFUw"
      },
      "outputs": [],
      "source": [
        "MODEL_URL = \"https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GGUF/resolve/main/mistral-7b-instruct-v0.2.Q5_K_M.gguf\"\n",
        "MODEL_PATH = \"/content/mistral-7b-instruct-v0.2.Q5_K_M.gguf\"\n",
        "\n",
        "if not os.path.exists(MODEL_PATH):\n",
        "    !wget -O {MODEL_PATH} {MODEL_URL}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEFEpecT4sC-"
      },
      "source": [
        "## 3. Load Local LLM (with GPU offload)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmxEwqWFyIse",
        "outputId": "7196a416-7cce-46e0-e8e9-13adc3d8c49d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_context: n_ctx_per_seq (4096) < n_ctx_train (32768) -- the full capacity of the model will not be utilized\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Dublin City Council is the local authority responsible for governing and managing the city of Dublin, Ireland. It is one of the 31 local authorities in Ireland and provides a range of services to the people living in its administrative area, which includes the city center and its suburbs. The council's main functions include housing, planning and development, roads and transportation, waste management, cultural and community services, and economic development. The council is elected every five years and is headed by a Lord Mayor,\n"
          ]
        }
      ],
      "source": [
        "from llama_cpp import Llama\n",
        "\n",
        "llm = Llama(\n",
        "    model_path=MODEL_PATH,\n",
        "    n_gpu_layers=-1,  # offload all layers to GPU\n",
        "    n_ctx=4096,\n",
        "    n_threads=8,\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "# Test\n",
        "response = llm.create_chat_completion(\n",
        "    messages=[{\"role\": \"user\", \"content\": \"What is Dublin City Council?\"}],\n",
        "    max_tokens=100\n",
        ")\n",
        "print(response['choices'][0]['message']['content'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yE4qh5Av4zPB"
      },
      "source": [
        "## 4. Scrape Dublin City Council Pages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "oLcZZ1cWyM6x"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "\n",
        "def scrape_page(url, filename):\n",
        "    res = requests.get(url)\n",
        "    soup = BeautifulSoup(res.text, 'html.parser')\n",
        "    # Remove scripts/styles\n",
        "    for script in soup([\"script\", \"style\"]):\n",
        "        script.decompose()\n",
        "    text = soup.get_text(separator=\"\\n\", strip=True)\n",
        "    with open(f\"/content/data/{filename}.txt\", \"w\") as f:\n",
        "        f.write(text)\n",
        "    print(f\"âœ… Saved: {filename}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpIrO5sfySz7",
        "outputId": "1fc4d73a-7cbb-4850-b75f-40c8663afb98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved: waste_recycling\n",
            "âœ… Saved: housing_support\n",
            "âœ… Saved: parking_permits\n"
          ]
        }
      ],
      "source": [
        "# Create data dir\n",
        "os.makedirs(\"/content/data\", exist_ok=True)\n",
        "\n",
        "# Scrape key pages\n",
        "pages = {\n",
        "    \"waste_recycling\": \"https://www.dublincity.ie/residential/waste-and-recycling\",\n",
        "    \"housing_support\": \"https://www.dublincity.ie/residential/housing\",\n",
        "    \"parking_permits\": \"https://www.dublincity.ie/residential/parking\"\n",
        "}\n",
        "\n",
        "for name, url in pages.items():\n",
        "    try:\n",
        "        scrape_page(url, name)\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Failed {name}: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYgBc0qm5DOk"
      },
      "source": [
        "## 5. Build FAISS RAG Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "K3W4PlibK3UH",
        "outputId": "5bae9e29-d108-4507-c062-04db90cfaa9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: unstructured in /usr/local/lib/python3.12/dist-packages (0.18.21)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from unstructured) (3.4.4)\n",
            "Requirement already satisfied: filetype in /usr/local/lib/python3.12/dist-packages (from unstructured) (1.2.0)\n",
            "Requirement already satisfied: python-magic in /usr/local/lib/python3.12/dist-packages (from unstructured) (0.4.27)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from unstructured) (6.0.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from unstructured) (3.9.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from unstructured) (2.32.5)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from unstructured) (4.13.5)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.12/dist-packages (from unstructured) (2.15.0)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.12/dist-packages (from unstructured) (0.6.7)\n",
            "Requirement already satisfied: python-iso639 in /usr/local/lib/python3.12/dist-packages (from unstructured) (2025.11.16)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.12/dist-packages (from unstructured) (1.0.9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from unstructured) (2.2.6)\n",
            "Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.12/dist-packages (from unstructured) (3.14.3)\n",
            "Requirement already satisfied: backoff in /usr/local/lib/python3.12/dist-packages (from unstructured) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from unstructured) (4.15.0)\n",
            "Requirement already satisfied: unstructured-client in /usr/local/lib/python3.12/dist-packages (from unstructured) (0.42.6)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from unstructured) (2.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from unstructured) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from unstructured) (5.9.5)\n",
            "Requirement already satisfied: python-oxmsg in /usr/local/lib/python3.12/dist-packages (from unstructured) (0.0.2)\n",
            "Requirement already satisfied: html5lib in /usr/local/lib/python3.12/dist-packages (from unstructured) (1.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->unstructured) (2.8)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json->unstructured) (3.26.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json->unstructured) (0.9.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.12/dist-packages (from html5lib->unstructured) (1.17.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from html5lib->unstructured) (0.5.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->unstructured) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->unstructured) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk->unstructured) (2025.11.3)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.12/dist-packages (from python-oxmsg->unstructured) (0.47)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->unstructured) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->unstructured) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->unstructured) (2025.11.12)\n",
            "Requirement already satisfied: aiofiles>=24.1.0 in /usr/local/lib/python3.12/dist-packages (from unstructured-client->unstructured) (24.1.0)\n",
            "Requirement already satisfied: cryptography>=3.1 in /usr/local/lib/python3.12/dist-packages (from unstructured-client->unstructured) (43.0.3)\n",
            "Requirement already satisfied: httpcore>=1.0.9 in /usr/local/lib/python3.12/dist-packages (from unstructured-client->unstructured) (1.0.9)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from unstructured-client->unstructured) (0.28.1)\n",
            "Requirement already satisfied: pydantic>=2.11.2 in /usr/local/lib/python3.12/dist-packages (from unstructured-client->unstructured) (2.12.3)\n",
            "Requirement already satisfied: pypdf>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from unstructured-client->unstructured) (6.5.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from unstructured-client->unstructured) (1.0.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=3.1->unstructured-client->unstructured) (2.0.0)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore>=1.0.9->unstructured-client->unstructured) (0.16.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured) (4.12.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.12/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->unstructured) (25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.11.2->unstructured-client->unstructured) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.11.2->unstructured-client->unstructured) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.11.2->unstructured-client->unstructured) (0.4.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured) (1.1.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=3.1->unstructured-client->unstructured) (2.23)\n"
          ]
        }
      ],
      "source": [
        "!pip install unstructured"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4Yf8rm-dh3Cx",
        "outputId": "684ffb21-9c56-4885-a551-f7745fa72cdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.9.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.36.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.5)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2.2.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.11.12)\n"
          ]
        }
      ],
      "source": [
        "!pip install sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "dc50f199480d4aaebd765df9c01bdce8",
            "4a2260b2a67048cd8e2ea3cfb4dacf73",
            "8eed2de123b5433c8f88f487f95596a9",
            "ef44a1db27f840fd811fe627edb96da6",
            "2e90a796cca94bcba9bb759593293f5f",
            "bd2f7e134c9d4b42b3c1b2aab6e762ef",
            "2f8c7ac5024d4da2827bcc03a6e6d126",
            "b8cf49242b98466dad2bbfd0cae1df19",
            "14aa0fe3e31f44579ba9abcb8a9872e1",
            "2ddb073a828d4546a65aa164caa90937",
            "9b26a67969444d3687d438e756267fc3",
            "a117c59394114105bc573971ca6edf5a",
            "c08689efdda54766ac432a7c03ed3947",
            "df9129576b354b3f8636e3858376a295",
            "028276ccefca439a89a04720b3843a12",
            "1413a8f05dea4463aec9123c4b96470c",
            "7a542116154d4914a3195b22ae9e23af",
            "176e5d72399a40238dccd55180dfb4ae",
            "da6e9b2b5d944d098b81d75dcae1357c",
            "d8b01c68937a4ebe97868d8a4cd77aec",
            "be24521491e042b1b531ecdf2185d22e",
            "b9cc47e479a0428fb168f6dbcd40211c",
            "255518aca18945caa4512c9b663cec16",
            "d33dd96a8a344fbf99c4fa8aa53df7b1",
            "18668ad4c90542fe93d2fd074f05b9a0",
            "4929ad7740de473db19fc28e6f09dc3e",
            "45fa5c9add2441f2b25edd4058c53129",
            "daf30ddb01934843aeeb0bd343980df5",
            "3556539ba92a4d939cbb0eb8b5cd366f",
            "19b847c276ec4f069e27b6c43139b342",
            "d977f1e829684ef3934eade9cc0b084e",
            "3a56a7c4a23b4146969331cdc20e4182",
            "3fb4cf9873814664b57afefe82d49af4",
            "d6f543264f404282bdc6ea98b4d38929",
            "2c4f46f6c3804b3a82d7f37c925cb068",
            "c9358351d1dc463c851b8d6109ef8de3",
            "2c7647f86b174b7aa3d43a33e719383b",
            "4ebdbb0cfcaa4b4b81da256dddb7f80e",
            "0fe0393eb30b434f90a04026420d3b79",
            "a0d667197811474192421f952b8f5694",
            "3551c7fb7a564d3b874a6de512115fcf",
            "e0c7fcf3db2341b98a4d47f4042c4a64",
            "2611e48d0ab14a9f85cfc3b0dd07b978",
            "531feaedf99d4ebbb724eeca96a63208",
            "45d8bd1aee314ba5a377b0b963589985",
            "0b24ef92849e458281161710a2321235",
            "95e7b45d3e794030803e049ed333309e",
            "9710d6b27d974dd09fece97ac9f28a93",
            "6b7b6aac1f4f4aceb074dc3a462d9278",
            "7b642fc0a9fe4efaba308c5871600d18",
            "900e1306ead9429b9840637b83c9a86d",
            "106f6d6bb1b2441e89971c9e9fa6ae5f",
            "cb418ff5a0ca4fa384da12e9c46a59ba",
            "f554de77e3d74f3c8b378b000b452065",
            "a6126fb11c4c47d3a792ca38b576e8b0",
            "5d4629f8175441fb898822682e6908c2",
            "0962c5a9bc1a4c80b045dc737ccb5d33",
            "009b17528133463b9023155e17325295",
            "b96c56ff84fb4606885e6beaef71d64f",
            "aebe24e64f294b83a506e23ee9c63538",
            "6ecf932b6a3949cdb2f7d60f5d1409f9",
            "02aacca2f8cd47e5878d014f05da36db",
            "3e262486b29348d8a957c18774ecb436",
            "96e07eb3050e45358907874a9ca13a3b",
            "4c10c0082c564a3f93be07a9c8aa8d59",
            "73359cccd80e4c5c820954bf32cb29b2",
            "ddb446dcd1654f8f96e70dc83adb89e4",
            "ad7a020ac95f4a28918372e73a9eb0a9",
            "5918a11ac91b4ebbb5782c4202ea3cc5",
            "89266a534b3b43989cea9ffc31eab4ce",
            "15a13b015f3b4b499acac4361bb11f7a",
            "082ce6bbedb64f6886fa509d030c7ad2",
            "679f1fe647504e54afcece02fe07810c",
            "c6a2de0ce51a493c9bb856c2769448c9",
            "867b21cc9a6b48be95d16074bb4bcea0",
            "385686308d194f9482c45d2d5b396e6d",
            "2516be1453b54bcbad5b5bec5e3cee90",
            "fbaf4e58f3444732b5a1138b0b775a3d",
            "5ec7d6f9a1bc40b1896ff929a9acb552",
            "040471273631416c8367dba98c651dd3",
            "54deb924cd6149c294f48f41915380e9",
            "6d166c02d2d546568a6ac745be4a58cc",
            "a0ab55cb862a464fb624e6b317df528f",
            "9f8c3d8f93fd48b7b94965ca692273ec",
            "2c955816d3954a4698acdd74867b146e",
            "e05fa1f264da45c796a58a4b23d8273b",
            "30fcd005a12c432a9ec1445d5dde2953",
            "304cfaed07164f9b853ddbb045caba62",
            "d9b7da21bde44856a328a7e0c8c8358f",
            "a51d2f1defaf41c692149711205a68d9",
            "fdd8189c78a7432e85422c6b51e020d4",
            "592c91bc47b34df68aa2fd5ebb1ea0e6",
            "d8b5f0949be344269792c3de992a7148",
            "4b53b64461aa44d1a841d9403ca67cd3",
            "e062da2a4dc54a99800e47a94eaf9508",
            "fe0d384669774e28b9fa8fdd6c5d6d23",
            "2d5a23a6e6004b4096cf7aeeb6eb904e",
            "72471f61cb444233b2a96d6ecbf27ed7",
            "1a9e52e1965c44128afcb2e0d77e3ee7",
            "69e200347dd84c228d18b70658eefbf5",
            "93b58e95f4284a29890748988bdd6775",
            "fe54a8df2fef41f0a4fe40d3e6a05948",
            "d0477e38d57c431a94231851b8509e53",
            "a942527eb05b452090fa7f167a941c92",
            "20c5e87430b440efaa5dd9bd5a1e2ddd",
            "a85ba40871ab43aa8b63f64f20715f5b",
            "ed1c396b3c2e4aa4a2ef9d8349febf67",
            "f5459c02ff1e44578327771cb6911012",
            "c5ec23e2fc1f43d6a583f51960c3705f",
            "e3c4d5265df34dfdb67e02ae0351daf6",
            "79a76f84abd54eeda897b7a900b45c6c",
            "38377516db2c4c058289da57dd897dda",
            "ba240cf3f22c4845bb3939adadb2b109",
            "71013b0411e74f258b72ca8745143db4",
            "ddc716e7c59d4f0f9f37ade9e7130e4f",
            "a0a710a3ef104e4cb61562712ea3a79f",
            "6c0a6024ee174132ac4a6ffa898b0d23",
            "4398690a723d4b098bb656f5f6cb9f37",
            "2f619ba38c9045a2bcfb2395a121828c",
            "b560b0b445f54492bf5139d951b80cdd",
            "9e1f511910484e01a4fa5ded13458eef"
          ]
        },
        "id": "SLv8O18syW8H",
        "outputId": "d9d61329-023a-49c4-d27b-1b31a5802399"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3359451929.py:15: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dc50f199480d4aaebd765df9c01bdce8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a117c59394114105bc573971ca6edf5a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "255518aca18945caa4512c9b663cec16"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d6f543264f404282bdc6ea98b4d38929"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "45d8bd1aee314ba5a377b0b963589985"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5d4629f8175441fb898822682e6908c2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ddb446dcd1654f8f96e70dc83adb89e4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fbaf4e58f3444732b5a1138b0b775a3d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d9b7da21bde44856a328a7e0c8c8358f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "69e200347dd84c228d18b70658eefbf5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "79a76f84abd54eeda897b7a900b45c6c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“„ Sample retrieval:\n",
            "Terms and Conditions\n",
            "\n",
            "Sitemap\n",
            "\n",
            ">\n",
            "\n",
            ">\n",
            "\n",
            "Statutory Obligations\n",
            "\n",
            "Freedom of Information\n",
            "\n",
            "GDPR and Data Protection\n",
            "\n",
            "Request Information on the Environment\n",
            "\n",
            "Protected Disclosure Procedures\n",
            "\n",
            "Lobbying\n",
            "\n",
            "Our Commitment to the Irish Language\n",
            "\n",
            "Councillor Ethics\n",
            "\n",
            "Public Sector Duty\n",
            "\n",
            "Bye Laws\n",
            "\n",
            "Procurement Policy a\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.document_loaders import DirectoryLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "# Load all scraped text\n",
        "loader = DirectoryLoader(\"/content/data/\", glob=\"*.txt\")\n",
        "docs = loader.load()\n",
        "\n",
        "# Split\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "chunks = splitter.split_documents(docs)\n",
        "\n",
        "# Embed & store\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "vectorstore = FAISS.from_documents(chunks, embeddings)\n",
        "retriever = vectorstore.as_retriever(k=3)\n",
        "\n",
        "# Test retriever\n",
        "print(\"ğŸ“„ Sample retrieval:\")\n",
        "print(retriever.invoke(\"bin collection exemption for students\")[0].page_content[:300])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrRxtqqx5RSe"
      },
      "source": [
        "## 6. Simulate Multi-Agent Workflow (CrewAI-style)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "7J85BXvA1D3F"
      },
      "outputs": [],
      "source": [
        "def researcher(query):\n",
        "    context = \" \".join([doc.page_content for doc in retriever.invoke(query)])\n",
        "    prompt = f\"\"\"You are a Dublin City Council policy researcher.\n",
        "Use ONLY the following context to answer the question.\n",
        "\n",
        "Context: {context}\n",
        "\n",
        "Question: {query}\n",
        "\n",
        "Answer (cite facts only):\"\"\"\n",
        "    return llm(prompt, max_tokens=256, stop=[\"\\n\\n\"])[\"choices\"][0][\"text\"].strip()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def validator(research_output, query):\n",
        "    prompt = f\"\"\"Based on this research: \"{research_output}\",\n",
        "is the citizen eligible for the requested service? Answer YES/NO and reason briefly.\n",
        "\n",
        "Citizen query: {query}\"\"\"\n",
        "    return llm(prompt, max_tokens=100)[\"choices\"][0][\"text\"].strip()\n",
        "\n",
        "\n",
        "def actioner(validated, query):\n",
        "    if \"YES\" in validated:\n",
        "        prompt = f\"\"\"Generate clear next steps for the citizen.\n",
        "Be specific: mention forms, emails, or documents needed.\n",
        "\n",
        "Citizen query: {query}\"\"\"\n",
        "    else:\n",
        "        prompt = f\"\"\"Politely explain why the citizen is not eligible and suggest alternatives.\n",
        "\n",
        "Citizen query: {query}\"\"\"\n",
        "    return llm(prompt, max_tokens=200)[\"choices\"][0][\"text\"].strip()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LwSk1Ia1yun",
        "outputId": "b7524847-c1d2-4749-ab3c-6f30e739c358"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ” RESEARCH:\n",
            " According to Dublin City Council's Terms and Conditions under the \"Waste and Recycling\" section, bin collection exemptions for students are subject to the following conditions:\n",
            "\n",
            "âœ… VALIDATION:\n",
            " Answer: YES, but the eligibility is subject to the conditions outlined in Dublin City Council's Terms and Conditions under the \"Waste and Recycling\" section. These conditions may include proof of student status and residency in a specific area. It is recommended that the citizen checks the exact requirements with Dublin City Council.\n",
            "\n",
            "ğŸ“¬ FINAL ANSWER:\n",
            " Assistant: To apply for a bin collection exemption in Harold's Cross, you'll need to contact your local authority, Dublin City Council, for assistance. You can reach them at [01 222 2222](ntouch://call/01%20222%202222 \"Call 01 222 2222 using Sorenson VRS\") or via email at waste.enquiries@dublincity.ie.\n",
            "\n",
            "In your request, please mention that you are a student and provide your student ID number or other proof of student status. You may also need to provide proof of address, such as a utility bill, to confirm your residency.\n",
            "\n",
            "Once your application has been reviewed, the council will contact you with the next steps or a decision regarding your exemption request.\n"
          ]
        }
      ],
      "source": [
        "def localgov_agent(query):\n",
        "    research = researcher(query)\n",
        "    validation = validator(research, query)\n",
        "    action = actioner(validation, query)\n",
        "    return {\n",
        "        \"research\": research,\n",
        "        \"validation\": validation,\n",
        "        \"final_answer\": action\n",
        "    }\n",
        "\n",
        "# Test\n",
        "test_query = \"I'm a student in Harold's Cross. Can I get a bin collection exemption?\"\n",
        "result = localgov_agent(test_query)\n",
        "print(\"ğŸ” RESEARCH:\\n\", result[\"research\"])\n",
        "print(\"\\nâœ… VALIDATION:\\n\", result[\"validation\"])\n",
        "print(\"\\nğŸ“¬ FINAL ANSWER:\\n\", result[\"final_answer\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1W6NPRBl5ZhD"
      },
      "source": [
        "## 7. Launch Gradio Demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "pDjEV8Hh12Y8",
        "outputId": "56f76dad-dcd1-4d6d-af70-1dffe53b51ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://672891fda9374e311e.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://672891fda9374e311e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "def chat_interface(user_query):\n",
        "    res = localgov_agent(user_query)\n",
        "    return res[\"final_answer\"]\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=chat_interface,\n",
        "    inputs=gr.Textbox(\n",
        "        lines=2,\n",
        "        placeholder=\"Ask anything about Dublin City Council services...\",\n",
        "        label=\"Your Question\"\n",
        "    ),\n",
        "    outputs=gr.Textbox(\n",
        "        lines=8,          # taller output\n",
        "        max_lines=20,     # allows scrolling if very long\n",
        "        label=\"Council AI Response\"\n",
        "    ),\n",
        "    title=\"ğŸ›ï¸ LocalGov AI Agent\",\n",
        "    description=\"An open-source agentic assistant for Dublin residents.\"\n",
        ")\n",
        "\n",
        "# Launch (public link will appear)\n",
        "demo.launch(share=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W1glGNTPPs_z"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
  },
  "nbformat": 4,
  "nbformat_minor": 0
}